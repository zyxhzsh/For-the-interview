1.如何解决过拟合

2.监督学习和无监督学习

3.常用监督学习和无监督学习的方法

4.贝叶斯公式

1.如何解决过拟合

过拟合是指模型对于训练数据拟合过当，模型在训练集上的表现很好，但在测试集和新数据上的表现较差。

（1）获得更多的训练数据，因为更多的样本能够让模型学习到更多更有效的特征，减小噪声的影响。使用更多的训练数据是解决过拟合问题最有效的手段。

可以通过一定的规则来扩充训练数据。比如，在图像分类的问题上，可以通过图像的平移、旋转、缩放等方式扩充数据;还可以使用生成式对抗网络来合成大量的新训练数据。

（2）降低模型复杂度。在数据较少时，模型过于复杂是产生过拟合的主要因素，适当降低模型复杂度可以避免模型拟合过多的采样噪声。

（3）降低数据集中样本的维度。

（4）正则化方法，给模型的参数加上一定的正则约束，比如将权值的大小加入到损失函数中。L2正则化是原来的损失函数加上权重参数的平方和。

正则化的目的是限制参数过多或者过大，避免模型更加复杂。

（5）集成学习方法。集成学习是把多个模型集成在一起，来降低单一模型的过拟合风险，如Bagging方法。

bagging，该方法通常考虑的是同质弱学习器，相互独立地并行学习这些弱学习器，并按照某种确定性的平均过程将它们组合起来。

boosting，该方法通常考虑的也是同质弱学习器。它以一种高度自适应的方法顺序地学习这些弱学习器（每个基础模型都依赖于前面的模型），并按照某种确定性的策略将它们组合起来。

2.监督学习和无监督学习

监督学习：利用有标签数据集生成一个模型。

无监督学习：只需要包含无标签样本的数据集。

3.常用监督学习和无监督学习的方法

#### 监督学习

knn：首先求出一个样本在特征空间中的k个最相似的样本，如果k个样本大多数属于某一个类别，则该样本也属于这一类别。KNN需要将训练数据保存在内存中，它是一个非参数化的算法。

决策树：决策树是一个可用于决策的非循环图。每个节点都有一个阈值，特征值小于阈值时选择左分支，否则选择右分支。当决策树到达叶节点时，可以用该叶节点的标签决定一个样本标签。

朴素贝叶斯：朴素贝叶斯分类是贝叶斯分类中最简单，是常见的一种分类方法。

### 无监督学习

k-means：（1)选择初始化的k个样本作为初始聚类中心。（2）对于每个样本xi，计算它到k个聚类中心的距离，并将其分到距离最短的中心所在的类。 （3）对每个类别，重新计算聚类中心。 （4）重复23步，直到达到终止条件(迭代次数、最小误差变化等)。

谱聚类：把所有的数据看做空间中的点，这些点之间用边连起来，距离较远的边权值低，距离较近的边权值大。对所有数据点组成的图进行切图，让切图后不同的子图间边权重和尽可能的低，而子图内的边权重和尽可能的高，从而达到聚类的目的。

PCA：是一种统计方法。通过正交变换将一组可能存在相关性的变量转换为一组线性不相关的变量，转换后的这组变量叫主成分。PCA常用于高维数据的降维。

4.贝叶斯公式

贝叶斯定理会根据一件事发生的先验知识告诉你它的后验概率。数学上它表示为:一个条件样本发生的真正率占真正率和假正率之和的比例。

（1）结果B发生的情况下原因A发生的概率为：A发生的条件下B发生的概率，乘以A发生的概率，除以B发生的概率。

（2）特征为B时，类别是A的概率 = 类别是A时，特征为B的概率，乘以类别为A的概率，除以类别为B的概率。
